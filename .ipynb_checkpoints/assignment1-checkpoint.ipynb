{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae597d45",
   "metadata": {},
   "source": [
    "# base_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary.word_frequency import WordFrequency\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Base class for dictionary implementations. DON'T CHANGE THIS FILE.\n",
    "#\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# -------------------------------------------------\n",
    "\n",
    "class BaseDictionary:\n",
    "    def build_dictionary(self, words_frequencies: [WordFrequency]):\n",
    "        \"\"\"\n",
    "        construct the data structure to store nodes\n",
    "        @param words_frequencies: list of (word, frequency) to be stored\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def search(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        search for a word\n",
    "        @param word: the word to be searched\n",
    "        @return: frequency > 0 if found and 0 if NOT found\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_word_frequency(self, word_frequency: WordFrequency) -> bool:\n",
    "        \"\"\"\n",
    "        add a word and its frequency to the dictionary\n",
    "        @param word_frequency: (word, frequency) to be added\n",
    "        @return: True whether succeeded, False when word is already in the dictionary\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def delete_word(self, word: str) -> bool:\n",
    "        \"\"\"\n",
    "        delete a word from the dictionary\n",
    "        @param word: word to be deleted\n",
    "        @return: whether succeeded, e.g. return False when point not found\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def autocomplete(self, prefix_word: str) -> [WordFrequency]:\n",
    "        \"\"\"\n",
    "        return a list of 3 most-frequent words in the dictionary that have 'prefix_word' as a prefix\n",
    "        @param prefix_word: word to be autocompleted\n",
    "        @return: a list (could be empty) of (at most) 3 most-frequent words with prefix 'prefix_word'\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e3dff",
   "metadata": {},
   "source": [
    "# list_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e00c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary.word_frequency import WordFrequency\n",
    "from dictionary.base_dictionary import BaseDictionary\n",
    "import time\n",
    "import math\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# This class is required TO BE IMPLEMENTED. List-based dictionary implementation.\n",
    "#\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "class ListDictionary(BaseDictionary):\n",
    "    def __init__(self):\n",
    "        self.data: list = None;\n",
    "\n",
    "    def partition(self, data, i, k, by):\n",
    "        midpoint = i + (k - i) // 2\n",
    "        pivot = getattr(data[midpoint], by)\n",
    "\n",
    "        done = False\n",
    "        l = i\n",
    "        h = k\n",
    "        while not done:\n",
    "            while getattr(data[l], by) < pivot:\n",
    "                l = l + 1\n",
    "            while pivot < getattr(data[h], by):\n",
    "                h = h - 1\n",
    "            if l >= h:\n",
    "                done = True\n",
    "            else:\n",
    "                temp = data[l]\n",
    "                data[l] = data[h]\n",
    "                data[h] = temp\n",
    "                l = l + 1\n",
    "                h = h - 1\n",
    "        return h\n",
    "\n",
    "    def quicksort(self, data, i, k, by: str):\n",
    "        j = 0\n",
    "        if i >= k:\n",
    "            return\n",
    "        j = self.partition(data, i, k, by)\n",
    "        self.quicksort(data, i, j, by)\n",
    "        self.quicksort(data, j + 1, k, by)\n",
    "        return\n",
    "\n",
    "    # merge sort algorithm sourced from Zybooks\n",
    "    def merge(self, data, i, j, k, by: str):\n",
    "        merged_size = k - i + 1  # Size of merged partition\n",
    "        merged_data = [0] * merged_size  # Dynamically allocates temporary array\n",
    "        # for merged numbers\n",
    "        merge_pos = 0  # Position to insert merged number\n",
    "        left_pos = i  # Initialize left partition position\n",
    "        right_pos = j + 1  # Initialize right partition position\n",
    "\n",
    "        # Add smallest element from left or right partition to merged numbers\n",
    "        while left_pos <= j and right_pos <= k:\n",
    "            if getattr(data[left_pos], by) <= getattr(data[right_pos], by):\n",
    "                merged_data[merge_pos] = data[left_pos]\n",
    "                left_pos += 1\n",
    "            else:\n",
    "                merged_data[merge_pos] = data[right_pos]\n",
    "                right_pos += 1\n",
    "            merge_pos = merge_pos + 1\n",
    "\n",
    "        # If left partition is not empty, add remaining elements to merged numbers\n",
    "        while left_pos <= j:\n",
    "            merged_data[merge_pos] = data[left_pos]\n",
    "            left_pos += 1\n",
    "            merge_pos += 1\n",
    "\n",
    "        # If right partition is not empty, add remaining elements to merged numbers\n",
    "        while right_pos <= k:\n",
    "            merged_data[merge_pos] = data[right_pos]\n",
    "            right_pos = right_pos + 1\n",
    "            merge_pos = merge_pos + 1\n",
    "\n",
    "        # Copy merge number back to numbers\n",
    "        for merge_pos in range(merged_size):\n",
    "            data[i + merge_pos] = merged_data[merge_pos]\n",
    "\n",
    "    def merge_sort(self, data, i, k, by: str):\n",
    "        j = 0\n",
    "\n",
    "        if i < k:\n",
    "            j = (i + k) // 2  # Find the midpoint in the partition\n",
    "\n",
    "            # Recursively sort left and right partitions\n",
    "            self.merge_sort(data, i, j, by)\n",
    "            self.merge_sort(data, j + 1, k, by)\n",
    "\n",
    "            # Merge left and right partition in sorted order\n",
    "            self.merge(data, i, j, k, by)\n",
    "\n",
    "    def __str__(self):\n",
    "        str = \"\"\n",
    "        for items in self.data:\n",
    "            str += f\"({items.word}, {items.frequency})\\n\"\n",
    "        return str\n",
    "\n",
    "    def build_dictionary(self, words_frequencies: [WordFrequency]):\n",
    "        \"\"\"\n",
    "        construct the data structure to store nodes\n",
    "        @param words_frequencies: list of (word, frequency) to be stored\n",
    "        \"\"\"\n",
    "        self.data = words_frequencies\n",
    "        # Merge-sort data (The time complexity of nlogn)\n",
    "        start_time = time.time_ns()\n",
    "        # self.quicksort(self.data, 0, len(self.data) - 1, \"word\")\n",
    "        self.data.sort(key=lambda x: x.word)\n",
    "        end_time = time.time_ns()\n",
    "\n",
    "        time_elapsed = (end_time - start_time) / math.pow(10, 9)\n",
    "        print(f\"Time elapsed (secs): {time_elapsed}\")\n",
    "\n",
    "    def binSearch(self, word:str) -> (bool, int):\n",
    "        \"\"\"\n",
    "        binary search for a word\n",
    "        @param word: the word to be searched\n",
    "        @return: (True, the index of word_frequencies) OR (False, the index of word_frequencies to be inserted into)\n",
    "        \"\"\"\n",
    "        low, mid, high = 0, 0, len(self.data) - 1\n",
    "\n",
    "        while low <= high:\n",
    "            mid = (low + high) // 2\n",
    "            if self.data[mid].word > word:\n",
    "                high = mid - 1\n",
    "            elif self.data[mid].word < word:\n",
    "                low = mid + 1\n",
    "            else:\n",
    "                return (True, mid)\n",
    "        return (False, mid)\n",
    "\n",
    "    def binSearchAC(self, prefix_word:str) -> int:\n",
    "        \"\"\"\n",
    "        binary search for a prefix\n",
    "        @param prefix: the prefix to be searched\n",
    "        @return: if found: the index of the first encountered word with the same prefix; if not: -1\n",
    "        \"\"\"\n",
    "        # The implementation is almost identical to binSearch except that prefix is compared to word upto its own length\n",
    "        low, mid, high = 0, 0, len(self.data) - 1\n",
    "\n",
    "        while low <= high:\n",
    "            mid = (low + high) // 2\n",
    "            if self.data[mid].word[:len(prefix_word)] > prefix_word:\n",
    "                high = mid - 1\n",
    "            elif self.data[mid].word[:len(prefix_word)] < prefix_word:\n",
    "                low = mid + 1\n",
    "            else:\n",
    "                return mid\n",
    "        return -1\n",
    "\n",
    "    def getAutocompleteList(self, prefix_word: str, idx: int) -> [WordFrequency]:\n",
    "        \"\"\"\n",
    "        add all the words sharing the same prefix_word to a list and return it unsorted\n",
    "        @param prefix_word: the prefix_word to be searched, idx: the starting index to search from in both directions (left and right)\n",
    "        @return: an unsorted list containing all the words sharing the same prefix_word\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        # Add the first word\n",
    "        res.append(self.data[idx])\n",
    "        left_idx = idx - 1\n",
    "        right_idx = idx + 1\n",
    "\n",
    "        if left_idx >= 0:\n",
    "            curr_left_word = self.data[left_idx].word[:len(prefix_word)]\n",
    "        # Add words to the left of the first word\n",
    "        while left_idx >= 0 and curr_left_word == prefix_word:\n",
    "            res.append(self.data[left_idx])\n",
    "            left_idx -= 1\n",
    "            curr_left_word = self.data[left_idx].word[:len(prefix_word)]\n",
    "\n",
    "        if right_idx <= len(self.data) - 1:\n",
    "            curr_right_word = self.data[right_idx].word[:len(prefix_word)]\n",
    "        # Add words to the right of the first word\n",
    "        while right_idx <= len(self.data) - 1 and curr_right_word == prefix_word:\n",
    "            res.append(self.data[right_idx])\n",
    "            right_idx += 1\n",
    "            curr_right_word = self.data[right_idx].word[:len(prefix_word)]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def search(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        search for a word\n",
    "        @param word: the word to be searched\n",
    "        @return: frequency > 0 if found and 0 if NOT found\n",
    "        \"\"\"\n",
    "        # Employ binary search\n",
    "        isFound, foundIdx = self.binSearch(word)\n",
    "        if not isFound:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.data[foundIdx].frequency\n",
    "\n",
    "    def add_word_frequency(self, word_frequency: WordFrequency) -> bool:\n",
    "        \"\"\"\n",
    "        add a word and its frequency to the dictionary\n",
    "        @param word_frequency: (word, frequency) to be added\n",
    "        :return: True whether succeeded, False when word is already in the dictionary\n",
    "        \"\"\"\n",
    "        # Employ binary search\n",
    "        word = word_frequency.word\n",
    "        isFound, foundIdx = self.binSearch(word)\n",
    "        actualLength = len(self.data)\n",
    "        if isFound:\n",
    "            return False\n",
    "        # If not found, add the word in self.data\n",
    "        else:\n",
    "            # Create space to shuffle elements to the right by 1\n",
    "            self.data.append(None)\n",
    "            for i in range(actualLength - 1, foundIdx - 1, -1):\n",
    "                self.data[i + 1] = self.data[i]\n",
    "            self.data[foundIdx] = word_frequency\n",
    "            return True\n",
    "\n",
    "    def delete_word(self, word: str) -> bool:\n",
    "        \"\"\"\n",
    "        delete a word from the dictionary\n",
    "        @param word: word to be deleted\n",
    "        @return: whether succeeded, e.g. return False when point not found\n",
    "        \"\"\"\n",
    "        isFound, foundIdx = self.binSearch(word)\n",
    "        if isFound:\n",
    "            for i in range(foundIdx, len(self.data) - 1):\n",
    "                self.data[i] = self.data[i + 1]\n",
    "            # In all cases, the last element will be deleted if the word is found\n",
    "            del self.data[-1]\n",
    "            return True\n",
    "        # If found, delete the word in self.data\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "    def autocomplete(self, prefix_word: str) -> [WordFrequency]:\n",
    "        \"\"\"\n",
    "        return a list of 3 most-frequent words in the dictionary that have 'prefix_word' as a prefix\n",
    "        @param prefix_word: word to be autocompleted\n",
    "        @return: a list (could be empty) of (at most) 3 most-frequent words with prefix 'prefix_word'\n",
    "        \"\"\"\n",
    "        # As soon as prefix_word matches with any word, scan all the words to its left and right and put them in a new list\n",
    "        # Iterate them only once to find the 3 most-frequent words\n",
    "        idx = self.binSearchAC(prefix_word)\n",
    "        if idx == -1:\n",
    "            return []\n",
    "        else:\n",
    "            lst = self.getAutocompleteList(prefix_word, idx)\n",
    "            self.merge_sort(lst, 0, len(lst) - 1, \"frequency\")\n",
    "            return lst[-3:][::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c970e52",
   "metadata": {},
   "source": [
    "# hashtable_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde39dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary.base_dictionary import BaseDictionary\n",
    "from dictionary.word_frequency import WordFrequency\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# This class is required TO BE IMPLEMENTED. Hash-table-based dictionary.\n",
    "#\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "class HashTableDictionary(BaseDictionary):\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def build_dictionary(self, words_frequencies: [WordFrequency]):\n",
    "        \"\"\"\n",
    "        construct the data structure to store nodes\n",
    "        @param words_frequencies: list of (word, frequency) to be stored\n",
    "        \"\"\"\n",
    "        self.data = {entry.word: entry.frequency for entry in words_frequencies}\n",
    "\n",
    "    def search(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        search for a word\n",
    "        @param word: the word to be searched\n",
    "        @return: frequency > 0 if found and 0 if NOT found\n",
    "        \"\"\"\n",
    "        return self.data.get(word, 0)\n",
    "\n",
    "    def add_word_frequency(self, word_frequency: WordFrequency) -> bool:\n",
    "        \"\"\"\n",
    "        add a word and its frequency to the dictionary\n",
    "        @param word_frequency: (word, frequency) to be added\n",
    "        :return: True whether succeeded, False when word is already in the dictionary\n",
    "        \"\"\"\n",
    "        freq = self.search(word_frequency.word)\n",
    "        if freq > 0:\n",
    "            return False\n",
    "        else:\n",
    "            self.data[word_frequency.word] = word_frequency.frequency\n",
    "            return True\n",
    "\n",
    "    def delete_word(self, word: str) -> bool:\n",
    "        \"\"\"\n",
    "        delete a word from the dictionary\n",
    "        @param word: word to be deleted\n",
    "        @return: whether succeeded, e.g. return False when point not found\n",
    "        \"\"\"\n",
    "        freq = self.search(word)\n",
    "        if freq > 0:\n",
    "            del self.data[word]\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def autocomplete(self, word: str) -> [WordFrequency]:\n",
    "        \"\"\"\n",
    "        return a list of 3 most-frequent words in the dictionary that have 'word' as a prefix\n",
    "        @param word: word to be autocompleted\n",
    "        @return: a list (could be empty) of (at most) 3 most-frequent words with prefix 'word'\n",
    "        \"\"\"\n",
    "        # Find the keys that start with a given prefix\n",
    "        autoDic = {key: freq for key, freq in self.data.items() if key.startswith(word)}\n",
    "        # Use Python's built-in sorting algorithm to sort autoDic by frequency and return the last three elements in descending order.\n",
    "        return [WordFrequency(key, freq) for key, freq in sorted(autoDic.items(), key=lambda item: item[1])][-3:][::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17642527",
   "metadata": {},
   "source": [
    "# tearnarysearchtree_dictionary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary.base_dictionary import BaseDictionary\n",
    "from dictionary.word_frequency import WordFrequency\n",
    "from dictionary.node import Node\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# This class is required to be implemented. Ternary Search Tree implementation.\n",
    "#\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class TernarySearchTreeDictionary(BaseDictionary):\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "\n",
    "    def build_dictionary(self, words_frequencies: [WordFrequency]):\n",
    "        \"\"\"\n",
    "        construct the data structure to store nodes\n",
    "        @param words_frequencies: list of (word, frequency) to be stored\n",
    "        \"\"\"\n",
    "        for idx, entry in enumerate(words_frequencies):\n",
    "            self.add_word_frequency(entry)\n",
    "\n",
    "    def search(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        search for a word\n",
    "        @param word: the word to be searched\n",
    "        @return: frequency > 0 if found and 0 if NOT found\n",
    "        \"\"\"\n",
    "        endNode = self.search_from_node(self.root, word, 0)\n",
    "        if endNode == None:\n",
    "            return 0\n",
    "        elif endNode.end_word == False:\n",
    "            return 0\n",
    "        else:\n",
    "            return endNode.frequency\n",
    "\n",
    "\n",
    "\n",
    "    def search_from_node(self, currNode, word, currIdx):\n",
    "        \"\"\"\n",
    "        search for a word recursively\n",
    "        @param node, word, currIdx: node to start from, the word to be searched, currIdx to search curLetter at\n",
    "        @return: frequency > 0 if found and 0 if NOT found\n",
    "        \"\"\"\n",
    "        currLetter = word[currIdx]\n",
    "        if currNode == None or currNode.letter == None:\n",
    "            return None\n",
    "        if currNode.letter < currLetter:\n",
    "            return self.search_from_node(currNode.right, word, currIdx)\n",
    "        elif currNode.letter > currLetter:\n",
    "            return self.search_from_node(currNode.left, word, currIdx)\n",
    "        elif currIdx < len(word) - 1:\n",
    "            return self.search_from_node(currNode.middle, word, currIdx + 1)\n",
    "        else:\n",
    "            return currNode\n",
    "\n",
    "\n",
    "    def add_word_frequency(self, word_frequency: WordFrequency) -> bool:\n",
    "        \"\"\"\n",
    "        add a word and its frequency to the dictionary\n",
    "        @param word_frequency: (word, frequency) to be added\n",
    "        :return: True whether succeeded, False when word is already in the dictionary\n",
    "        \"\"\"\n",
    "        return self.add_word_from_root(self.root, word_frequency.word, word_frequency.frequency, 0)\n",
    "\n",
    "    def add_word_from_root(self, currNode, word, freq, currIdx) -> bool:\n",
    "        \"\"\"\n",
    "        add a word recursively\n",
    "        @param currNode, word, freq, currIdx: currNode initially self.root; currIdx is used for the base case.\n",
    "        :return: True if addition is successful, false if the word being added already exists.\n",
    "        \"\"\"\n",
    "        currLetter = word[currIdx]\n",
    "        # Base case on the last word\n",
    "        if currIdx == len(word) - 1:\n",
    "            if currNode.letter == None:\n",
    "                currNode.letter = currLetter\n",
    "                currNode.frequency = freq\n",
    "                currNode.end_word = True\n",
    "                return True\n",
    "            # If currNode is the same as curLetter\n",
    "            else:\n",
    "                if currNode.letter > currLetter:\n",
    "                    if currNode.left == None:\n",
    "                        currNode.left = Node()\n",
    "                    currNode = currNode.left\n",
    "                    return self.add_word_from_root(currNode, word, freq, currIdx)\n",
    "                elif currNode.letter < currLetter:\n",
    "                    if currNode.right == None:\n",
    "                        currNode.right = Node()\n",
    "                    currNode = currNode.right\n",
    "                    return self.add_word_from_root(currNode, word, freq, currIdx)\n",
    "                else:\n",
    "                    if currNode.end_word == True:\n",
    "                        return False\n",
    "                    else:\n",
    "                        currNode.frequency = freq\n",
    "                        currNode.end_word = True\n",
    "                        return True\n",
    "        # Recursive case\n",
    "        else:\n",
    "            # When no word is present\n",
    "            if currNode.letter == None:\n",
    "                currNode.letter = currLetter\n",
    "                currNode.middle = Node()\n",
    "                currNode = currNode.middle\n",
    "                return self.add_word_from_root(currNode, word, freq, currIdx + 1)\n",
    "            elif currNode.letter < currLetter:\n",
    "                if currNode.right == None:\n",
    "                    currNode.right = Node()\n",
    "                currNode = currNode.right\n",
    "                return self.add_word_from_root(currNode, word, freq, currIdx)\n",
    "            elif currNode.letter > currLetter:\n",
    "                if currNode.left == None:\n",
    "                    currNode.left = Node()\n",
    "                currNode = currNode.left\n",
    "                return self.add_word_from_root(currNode, word, freq, currIdx)\n",
    "            else:\n",
    "                if currNode.middle == None:\n",
    "                    currNode.middle = Node()\n",
    "                currNode = currNode.middle\n",
    "                return self.add_word_from_root(currNode, word, freq, currIdx + 1)\n",
    "\n",
    "    def delete_word(self, word: str) -> bool:\n",
    "        \"\"\"\n",
    "        delete a word from the dictionary\n",
    "        @param word: word to be deleted\n",
    "        @return: whether succeeded, e.g. return False when point not found\n",
    "        \"\"\"\n",
    "        # First, search for a word\n",
    "        endNode = self.search_from_node(self.root, word, 0)\n",
    "        if not endNode or endNode.end_word == False:\n",
    "            return False\n",
    "        else:\n",
    "            endNode.frequency = None\n",
    "            endNode.end_word = False\n",
    "        return True\n",
    "\n",
    "    def add_ac_words(self, currNode: Node, compoundWord: str, ac_lst: list) -> [WordFrequency]:\n",
    "        \"\"\"\n",
    "        Recursively traverse all the children nodes of currNode and create an instance of WordFrequency\n",
    "        using compoundWord and the frequency of currNode if its end_word is True.\n",
    "        @param currNode, compoundWord, ac_lst: compoundWord to keep track of the word to be added\n",
    "        ac_lst: the list to which an instance of WordFrequency is added\n",
    "        @return: a list (could be empty) of all the words with prefix 'word'\n",
    "        \"\"\"\n",
    "\n",
    "        # Base Case 1: currNode is None\n",
    "        if currNode == None:\n",
    "            return\n",
    "        # Recursive case:\n",
    "        else:\n",
    "            if currNode.end_word == True:\n",
    "                ac_lst.append(WordFrequency(compoundWord + currNode.letter, currNode.frequency))\n",
    "            self.add_ac_words(currNode.left, compoundWord, ac_lst)\n",
    "            self.add_ac_words(currNode.middle, compoundWord + currNode.letter, ac_lst)\n",
    "            self.add_ac_words(currNode.right, compoundWord, ac_lst)\n",
    "\n",
    "    def autocomplete(self, word: str) -> [WordFrequency]:\n",
    "        \"\"\"\n",
    "        return a list of 3 most-frequent words in the dictionary that have 'word' as a prefix\n",
    "        @param word: word to be autocompleted\n",
    "        @return: a list (could be empty) of (at most) 3 most-frequent words with prefix 'word'\n",
    "        \"\"\"\n",
    "        # a list of words to be autocompleted\n",
    "        ac_lst = []\n",
    "\n",
    "        # Find the prefix\n",
    "        currNode = self.search_from_node(self.root, word, 0)\n",
    "\n",
    "        # If the prefix does not exist\n",
    "        if not currNode:\n",
    "            return ac_lst\n",
    "        else:\n",
    "            # If the currNode's end_word is true\n",
    "            if currNode.end_word == True:\n",
    "                ac_lst.append(WordFrequency(word, currNode.frequency))\n",
    "            self.add_ac_words(currNode.middle, word, ac_lst)\n",
    "\n",
    "            # Python's built-in Timsort\n",
    "            ac_lst.sort(key=lambda wordFrequency: wordFrequency.frequency, reverse=True)\n",
    "\n",
    "        return ac_lst[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5e75f",
   "metadata": {},
   "source": [
    "# word_frequency.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Class representing a word and its frequency\n",
    "class WordFrequency:\n",
    "    def __init__(self, word: str, frequency: int):\n",
    "        self.word = word\n",
    "        self.frequency = frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fab07",
   "metadata": {},
   "source": [
    "# node.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# -------------------------------------------------\n",
    "\n",
    "# DON'T CHANGE THIS FILE\n",
    "# Class representing a node in the Ternary Search Tree\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, letter=None, frequency=None, end_word=False):\n",
    "        self.letter = letter            # letter stored at this node\n",
    "        self.frequency = frequency      # frequency of the word if this letter is the end of a word\n",
    "        self.end_word = end_word        # True if this letter is the end of a word\n",
    "        self.left = None    # pointing to the left child Node, which holds a letter < self.letter\n",
    "        self.middle = None  # pointing to the middle child Node\n",
    "        self.right = None   # pointing to the right child Node, which holds a letter > self.letter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94e1d8",
   "metadata": {},
   "source": [
    "# dictionary_file_based.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dictionary.node import Node\n",
    "from dictionary.word_frequency import WordFrequency\n",
    "from dictionary.base_dictionary import BaseDictionary\n",
    "from dictionary.list_dictionary import ListDictionary\n",
    "from dictionary.hashtable_dictionary import HashTableDictionary\n",
    "from dictionary.ternarysearchtree_dictionary import TernarySearchTreeDictionary\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# DON'T CHANGE THIS FILE.\n",
    "# This is the entry point to run the program in file-based mode.\n",
    "# It uses the data file to initialise the set of words & frequencies.\n",
    "# It takes a command file as input and output into the output file.\n",
    "# Refer to usage() for exact format of input expected to the program.\n",
    "#\n",
    "# __author__ = 'Son Hoang Dau'\n",
    "# __copyright__ = 'Copyright 2022, RMIT University'\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def usage():\n",
    "    \"\"\"\n",
    "    Print help/usage message.\n",
    "    \"\"\"\n",
    "    print('python3 dictionary_file_based.py', '<approach> [data fileName] [command fileName] [output fileName]')\n",
    "    print('<approach> = <list | hashtable | tst>')\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Fetch the command line arguments\n",
    "    args = sys.argv\n",
    "\n",
    "    if len(args) != 5:\n",
    "        print('Incorrect number of arguments.')\n",
    "        usage()\n",
    "\n",
    "    # initialise search agent\n",
    "    agent: BaseDictionary = None\n",
    "    if args[1] == 'list':\n",
    "        agent = ListDictionary()\n",
    "    elif args[1] == 'hashtable':\n",
    "        agent = HashTableDictionary()\n",
    "    elif args[1] == 'tst':\n",
    "        agent = TernarySearchTreeDictionary()\n",
    "    else:\n",
    "        print('Incorrect argument value.')\n",
    "        usage()\n",
    "\n",
    "    # read from data file to populate the initial set of points\n",
    "    data_filename = args[2]\n",
    "    words_frequencies_from_file = []\n",
    "    try:\n",
    "        data_file = open(data_filename, 'r')\n",
    "        for line in data_file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            frequency = int(values[1])\n",
    "            word_frequency = WordFrequency(word, frequency)  # each line contains a word and its frequency\n",
    "            words_frequencies_from_file.append(word_frequency)\n",
    "        data_file.close()\n",
    "        agent.build_dictionary(words_frequencies_from_file)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Data file doesn't exist.\")\n",
    "        usage()\n",
    "\n",
    "    command_filename = args[3]\n",
    "    output_filename = args[4]\n",
    "    # Parse the commands in command file\n",
    "    try:\n",
    "        command_file = open(command_filename, 'r')\n",
    "        output_file = open(output_filename, 'w')\n",
    "\n",
    "        for line in command_file:\n",
    "            command_values = line.split()\n",
    "            command = command_values[0]\n",
    "            # search\n",
    "            if command == 'S':\n",
    "                word = command_values[1]\n",
    "                search_result = agent.search(word)\n",
    "                if search_result > 0:\n",
    "                    output_file.write(f\"Found '{word}' with frequency {search_result}\\n\")\n",
    "                else:\n",
    "                    output_file.write(f\"NOT Found '{word}'\\n\")\n",
    "\n",
    "            # add\n",
    "            elif command == 'A':\n",
    "                word = command_values[1]\n",
    "                frequency = int(command_values[2])\n",
    "                word_frequency = WordFrequency(word, frequency)\n",
    "                if not agent.add_word_frequency(word_frequency):\n",
    "                    output_file.write(f\"Add '{word}' failed\\n\")\n",
    "                else:\n",
    "                    output_file.write(f\"Add '{word}' succeeded\\n\")\n",
    "\n",
    "            # delete\n",
    "            elif command == 'D':\n",
    "                word = command_values[1]\n",
    "                if not agent.delete_word(word):\n",
    "                    output_file.write(f\"Delete '{word}' failed\\n\")\n",
    "                else:\n",
    "                    output_file.write(f\"Delete '{word}' succeeded\\n\")\n",
    "\n",
    "            # check\n",
    "            elif command == 'AC':\n",
    "                word = command_values[1]\n",
    "                list_words = agent.autocomplete(word)\n",
    "                line = \"Autocomplete for '\" + word + \"': [ \"\n",
    "                for item in list_words:\n",
    "                    line = line + item.word + \": \" + str(item.frequency) + \" \"\n",
    "                output_file.write(line + ']\\n')\n",
    "\n",
    "            else:\n",
    "                print('Unknown command.')\n",
    "                print(line)\n",
    "\n",
    "        output_file.close()\n",
    "        command_file.close()\n",
    "\n",
    "        # Compare exp to actual\n",
    "        expFileName = args[3][:-2] + \"exp\"\n",
    "        actualFileName = args[4]\n",
    "        with open (expFileName) as test:\n",
    "            with open (actualFileName) as actual:\n",
    "                testOut = ''.join(test.readlines()).strip()\n",
    "                actualOut = ''.join(actual.readlines()).strip()\n",
    "                if testOut == actualOut:\n",
    "                    print(f\"PASSED - {expFileName} and {actualFileName} are identical\")\n",
    "                else:\n",
    "                    print(f\"FAILED - {expFileName} and {actualFileName} are different\")\n",
    "\n",
    "        # Print the dictionary\n",
    "        # print(\"The contents of the dictionary are:\")\n",
    "        # print(agent)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Command file doesn't exist.\")\n",
    "        usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097568ce",
   "metadata": {},
   "source": [
    "## General plan for the Empirical Analysis of Algorithm Time Efficiency\n",
    "\n",
    "1. Understand the experiment's purpose\n",
    "    - to find which data structure is most appropriate for given scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab97792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
